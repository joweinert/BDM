x-common: &common-settings
  environment:
    # Pass all environment variables from .env to each service
    &env-vars # Airflow Database
    POSTGRES_USER: ${POSTGRES_USER}
    POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    POSTGRES_DB: ${POSTGRES_DB}
    # Airflow Admin Credentials
    AIRFLOW_ADMIN_USERNAME: ${AIRFLOW_ADMIN_USERNAME}
    AIRFLOW_ADMIN_PASSWORD: ${AIRFLOW_ADMIN_PASSWORD}
    AIRFLOW_ADMIN_FIRSTNAME: ${AIRFLOW_ADMIN_FIRSTNAME}
    AIRFLOW_ADMIN_LASTNAME: ${AIRFLOW_ADMIN_LASTNAME}
    AIRFLOW_ADMIN_EMAIL: ${AIRFLOW_ADMIN_EMAIL}
    # Spark
    SPARK_MASTER_URL: ${SPARK_MASTER_URL}
    # MinIO
    MINIO_ENDPOINT: ${MINIO_ENDPOINT}
    MINIO_ROOT_USER: ${MINIO_ROOT_USER}
    MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    MINIO_DATA_BUCKET: ${MINIO_DATA_BUCKET}
    MINIO_SCRIPT_BUCKET: ${MINIO_SCRIPT_BUCKET}
    MINIO_UNSTRUCTURED_BUCKET: ${MINIO_UNSTRUCTURED_BUCKET}
    # Kafka
    KAFKA_BROKER: ${KAFKA_BROKER}

services:
  postgres:
    <<: *common-settings
    image: postgres:latest
    container_name: airflow_postgres
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 10s
      retries: 5
      start_period: 5s
    restart: always
    environment:
      <<: *env-vars
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data

  airflow-init:
    <<: *common-settings
    image: apache/airflow:latest
    container_name: airflow_init
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      <<: *env-vars
      _AIRFLOW_DB_MIGRATE: "true"
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres/${POSTGRES_DB}
      _AIRFLOW_WWW_USER_CREATE: "true"
      _AIRFLOW_WWW_USER_USERNAME: ${AIRFLOW_ADMIN_USERNAME}
      _AIRFLOW_WWW_USER_PASSWORD: ${AIRFLOW_ADMIN_PASSWORD}
      _AIRFLOW_WWW_USER_FIRSTNAME: ${AIRFLOW_ADMIN_FIRSTNAME}
      _AIRFLOW_WWW_USER_LASTNAME: ${AIRFLOW_ADMIN_LASTNAME}
      _AIRFLOW_WWW_USER_EMAIL: ${AIRFLOW_ADMIN_EMAIL}
      _AIRFLOW_WWW_USER_ROLE: Admin
    command: airflow version

  airflow-scheduler:
    <<: *common-settings
    build:
      context: .
      dockerfile: docker/airflow/Dockerfile
    container_name: airflow-scheduler
    restart: always
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    command: scheduler
    environment:
      <<: *env-vars
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres/${POSTGRES_DB}
      AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK: "true"
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8974/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    volumes:
      - ./src/batch/dags:/opt/airflow/dags
      - ./docker/airflow/logs:/opt/airflow/logs
      - /var/run/docker.sock:/var/run/docker.sock

  airflow-webserver:
    <<: *common-settings
    build:
      context: .
      dockerfile: docker/airflow/Dockerfile
    container_name: airflow-webserver
    restart: always
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    command: webserver
    ports:
      - "8080:8080"
    environment:
      <<: *env-vars
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres/${POSTGRES_DB}
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    volumes:
      - ./src/batch/dags:/opt/airflow/dags
      - ./docker/airflow/logs:/opt/airflow/logs

  minio:
    <<: *common-settings
    build:
      context: .
      dockerfile: docker/minio/Dockerfile
      args:
        MINIO_ROOT_USER: ${MINIO_ROOT_USER}
        MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
        MINIO_SCRIPT_BUCKET: ${MINIO_SCRIPT_BUCKET}
        MINIO_DATA_BUCKET: ${MINIO_DATA_BUCKET}
        MINIO_UNSTRUCTURED_BUCKET: ${MINIO_UNSTRUCTURED_BUCKET}
    container_name: minio
    restart: always
    environment:
      <<: *env-vars
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio_data:/data

  spark-master:
    <<: *common-settings
    build:
      context: .
      dockerfile: docker/spark/Dockerfile
    container_name: spark-master
    environment:
      <<: *env-vars
      SPARK_MODE: master
      SPARK_RPC_AUTHENTICATION_ENABLED: no
      SPARK_RPC_ENCRYPTION_ENABLED: no
      SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED: no
      SPARK_SSL_ENABLED: no
      SPARK_USER: spark
    ports:
      - "7077:7077"
      - "8081:8080"
    volumes:
      - ./src/batch/pipelines:/opt/bitnami/spark/pipelines

  spark-worker-1:
    <<: *common-settings
    build:
      context: .
      dockerfile: docker/spark/Dockerfile
    container_name: spark-worker-1
    environment:
      <<: *env-vars
      SPARK_MODE: worker
      SPARK_USER: spark
    depends_on:
      - spark-master
    volumes:
      - ./src/batch/pipelines:/opt/bitnami/spark/pipelines

  spark-worker-2:
    <<: *common-settings
    build:
      context: .
      dockerfile: docker/spark/Dockerfile
    container_name: spark-worker-2
    environment:
      <<: *env-vars
      SPARK_MODE: worker
      SPARK_USER: spark
    depends_on:
      - spark-master
    volumes:
      - ./src/batch/pipelines:/opt/bitnami/spark/pipelines

  zookeeper:
    <<: *common-settings
    image: confluentinc/cp-zookeeper:latest
    container_name: zookeeper
    restart: always
    environment:
      <<: *env-vars
      ZOOKEEPER_CLIENT_PORT: 2181
    ports:
      - "2181:2181"

  kafka:
    <<: *common-settings
    image: confluentinc/cp-kafka:latest
    container_name: kafka
    restart: always
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      <<: *env-vars
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,PLAINTEXT_HOST://0.0.0.0:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "9092"]
      interval: 3s
      retries: 30
      start_period: 5s

  producer:
    <<: *common-settings
    build:
      context: .
      dockerfile: docker/kafka/Dockerfile
    container_name: kafka_producer
    restart: always
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      <<: *env-vars
      DOCKER_ENV: "true"
    command: ["python", "streaming/producer/kafka_producer.py"]

  crypto_producer:
    <<: *common-settings
    build:
      context: .
      dockerfile: docker/kafka/Dockerfile
    container_name: crypto_producer
    restart: always
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      <<: *env-vars
      DOCKER_ENV: "true"
    command: ["python", "streaming/producer/crypto_producer.py"]

  image_producer:
    <<: *common-settings
    build:
      context: .
      dockerfile: docker/kafka/Dockerfile
    container_name: image_producer
    restart: always
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      <<: *env-vars
      DOCKER_ENV: "true"
    command: ["python", "streaming/producer/image_producer.py"]
    volumes:
      - ./images:/app/images

  consumer:
    <<: *common-settings
    build:
      context: .
      dockerfile: docker/kafka/Dockerfile
    container_name: kafka_consumer
    restart: always
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      <<: *env-vars
      DOCKER_ENV: "true"
    command: ["python", "streaming/consumer/kafka_consumer.py"]

  crypto_consumer:
    <<: *common-settings
    build:
      context: .
      dockerfile: docker/kafka/Dockerfile
    container_name: crypto_consumer
    restart: always
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      <<: *env-vars
      DOCKER_ENV: "true"
    command: ["python", "streaming/consumer/crypto_consumer.py"]

  image_consumer:
    <<: *common-settings
    build:
      context: .
      dockerfile: docker/kafka/Dockerfile
    container_name: image_consumer
    restart: always
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      <<: *env-vars
      DOCKER_ENV: "true"
    command: ["python", "streaming/consumer/image_consumer.py"]

volumes:
  postgres-db-volume:
  minio_data:
